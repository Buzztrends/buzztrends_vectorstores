{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(os.environ[\"MONGO_CONNECTION_STRING\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_db = mongo_client[\"users\"][\"user-data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = user_db.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_moments = user[\"moments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in cursor:\n",
    "    _id = user[\"company_id\"]\n",
    "    new_moments = {\n",
    "        \"General News\":[\"A\", \"bf\", \"XC\"],\n",
    "        \"Industry News\":[\"A\", \"bfa\", \"XC\"],\n",
    "        \"Current Events\":[\"A\", \"basd\", \"XC\"],\n",
    "        \"social_media\":[\"A\", \"b\", \"XCsad\"],\n",
    "    }\n",
    "\n",
    "    new_values = {\"$set\": {\"moments\": new_moments}}\n",
    "    print(user_db.update_one({\"company_id\":_id}, new_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chroma_interface.reader import Reader\n",
    "from chroma_interface.writer import Writer\n",
    "import os\n",
    "\n",
    "keys = list(open(\".env\", \"r\"))\n",
    "\n",
    "for item in keys:\n",
    "    variable, value = item.split(\"=\")[0], \"=\".join(item.split(\"=\")[1:])\n",
    "    os.environ[variable] = value.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "chroma_host = os.environ[\"CHROMA_IP\"]\n",
    "\n",
    "reader = Reader(host=chroma_host, port=8000, collection=\"test-1\", openai_api_key=openai_key)\n",
    "writer = Writer(host=chroma_host, port=8000, openai_api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = reader.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.simple_utils import *\n",
    "from utils.google_utils import *\n",
    "from utils.langchain_utils import *\n",
    "from utils.best_hashtags import *\n",
    "\n",
    "from mongo.interface import *\n",
    "\n",
    "from chroma_interface import *\n",
    "from chroma_interface.reader import *\n",
    "from chroma_interface.writer import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "# Constants\n",
    "NEWS_TOPICS = read_lines_from_file(\"./config/topic-type.txt\")\n",
    "\n",
    "COUNTRY_NAMES = read_lines_from_file(\"./config/countries-names.txt\")\n",
    "COUNTRY_CODES = defaultdict(None)\n",
    "for name, code in zip(COUNTRY_NAMES, read_lines_from_file(\"./config/countries-code.txt\")):\n",
    "    COUNTRY_CODES[name] = code\n",
    "\n",
    "COUNTRY_CODES_TO_NAMES = defaultdict(None)\n",
    "for name, code in zip(COUNTRY_NAMES, read_lines_from_file(\"./config/countries-code.txt\")):\n",
    "    COUNTRY_CODES_TO_NAMES[code] = name\n",
    "\n",
    "QUERY_KEYWORDS_DICT = json.load(open(\"./config/query-topics.json\", 'r'))\n",
    "QUERY_TOPICS = list(QUERY_KEYWORDS_DICT.keys())\n",
    "\n",
    "QUERY_KEYWORDS = []\n",
    "for item in QUERY_KEYWORDS_DICT.values():\n",
    "    QUERY_KEYWORDS.extend(item)\n",
    "\n",
    "\n",
    "# environment setup\n",
    "with open(\".env\", \"r\") as key_file:\n",
    "    keys = list(key_file)\n",
    "\n",
    "for item in keys:\n",
    "    variable, value = item.split(\"=\")[0], \"=\".join(item.split(\"=\")[1:])\n",
    "    os.environ[variable] = value.replace(\"\\n\", \"\")\n",
    "\n",
    "topic=NEWS_TOPICS[0]\n",
    "country_name = \"India\"\n",
    "country_code=COUNTRY_CODES[country_name]\n",
    "lang='en'\n",
    "collection_name = \"general_news\"\n",
    "\n",
    "chroma_reader, chroma_writer = get_reader_writer(\n",
    "    host=os.environ[\"CHROMA_IP\"],\n",
    "    port=int(os.environ[\"CHROMA_PORT\"]),\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    reader_collection_name=collection_name\n",
    ")\n",
    "\n",
    "user_mongo_client = MongoInterface(\n",
    "    url=os.environ[\"MONGO_CONNECTION_STRING\"],\n",
    "    database=\"users\",\n",
    "    collection=\"user-data\"\n",
    ")\n",
    "\n",
    "from scripts import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist = user_mongo_client.get_user_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist = list(userlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('659b859e5b1eff3e23a572ae'),\n",
       "  'company_id': 1450967627,\n",
       "  'company_name': 'Incommon',\n",
       "  'username': 'piyush',\n",
       "  'password': 'JDJiJDEyJFlONVAzSkhEVmpjNXVNYXVuMHM3OXVaa0Y3emkvUk55Lk55akk3VXh3ZENUdGtTQVZHYlRL',\n",
       "  'company_description': \"This is a company that helps businesses hire vetted overseas talent. If this is the InCommon you're interested in, I could write a blurb about how it can help businesses save money and find top talent.\",\n",
       "  'content_category': 'Hiring, Talent acquisition, Global talent hiring.',\n",
       "  'country': 'India',\n",
       "  'country_code': 'IN',\n",
       "  'generation_available': 99,\n",
       "  'products': {},\n",
       "  'moments': None,\n",
       "  'saved_posts': {'under_review': [], 'reviewed': [], 'live': []},\n",
       "  'last_5_generations': [],\n",
       "  'saved_topics': []},\n",
       " {'_id': ObjectId('659bf9f649412ae11703fc09'),\n",
       "  'company_id': 4249443146,\n",
       "  'company_name': 'Marico',\n",
       "  'username': 'marico',\n",
       "  'password': 'JDJiJDEyJDdyUmZ2WnhXaGgyQUxQU0pUVGJ1cU9ac3gwRFU2YTFrN3NMeXdHT3kxaVluVTFQaURZOGUy',\n",
       "  'company_description': \"Marico Ltd. is an Indian consumer goods company based in Mumbai, Maharashtra. The company's main products are hair care, skin care, edible oils, and food products. Marico's most popular brands include Parachute coconut oil, Saffola edible oils, Livon hair serum, and Nihar Naturals shampoo.\",\n",
       "  'content_category': 'hair care, skin care, edible oils,food products.',\n",
       "  'country': 'India',\n",
       "  'country_code': 'IN',\n",
       "  'generation_available': 99,\n",
       "  'products': {'Parachute Coconut Oil 600 ml - Bottle': {'Description': 'Handpicked coconuts, 100% pure oil, fresh fragrance, long-lasting purity â€“ 27 tests & 5-stage process for your perfect scoop.',\n",
       "    'Price': 'INR 220'},\n",
       "   'Set Wet Styling Hair Gel for Men - Casually Cool, 100gm': {'Description': 'Set Wet Casually Cool: Pro-vitamin B5 for sexy, healthy hair, quick casual styling, natural shine, effortless all-day hold, free of nasty chemicals, perfect for any hair type, casual outings, coin-sized application, washes out with water.',\n",
       "    'Price': 'INR 85'},\n",
       "   'SAFFOLA GOLD, PRO HEALTHY LIFESTYLE EDIBLE OIL - 5 L JAR': {'Description': 'Saffola Gold: 2 oils in 1 (rice bran & sunflower) for balanced MUFA & PUFA, immunity boost, cholesterol control, Oryzanol for healthy cholesterol, LOSORB tech for 33% less oil absorption, preserves food flavor, 5L, 9 months shelf life, made in India.',\n",
       "    'Price': 'INR 1000'}},\n",
       "  'moments': None,\n",
       "  'saved_posts': {'under_review': [], 'reviewed': [], 'live': []},\n",
       "  'last_5_generations': [],\n",
       "  'saved_topics': []}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlist[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 3894336111\n",
    "user_data = user_mongo_client.get_user(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments=[item[\"title\"] for item in user_data[\"moments\"]['social_media_trends']]\n",
    "moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords_and_tokenize(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def remove_stopwords_and_tokenize(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def pos_tagging(tokens):\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    return tagged_tokens\n",
    "\n",
    "def grams(string, max_n=3):\n",
    "    string = string.replace(\"#\", \"\")\n",
    "    \n",
    "    length = len(string.split())\n",
    "\n",
    "    length = max_n if length > max_n else length\n",
    "\n",
    "    ngrams_data = []\n",
    "    for i in range(length+1):\n",
    "        \n",
    "        ngrams_data.extend(ngrams(remove_stopwords_and_tokenize(string), i))\n",
    "\n",
    "    return [\"\".join(item).lower() for item in ngrams_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = moments[0]\n",
    "hashtag_queries = grams(test)\n",
    "\n",
    "hashtag_data = {}\n",
    "\n",
    "for query in hashtag_queries:\n",
    "    hashtag_data.update(get_hashtag_data(query))\n",
    "    \n",
    "hashtag_data = pd.Series(hashtag_data)\n",
    "hashtag_data.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed hashtag query: cosmetic\n",
      "[GET] Related hashtags\n",
      "parsed hashtag query: minimalism\n",
      "[GET] Related hashtags\n",
      "parsed hashtag query: cosmeticminimalism\n",
      "[GET] Related hashtags\n",
      "no data in related\n",
      "[GET] Easy hashtags for cosmeticminimalism\n",
      "No data in easy\n",
      "[GET] Medium hashtags\n",
      "No data in medium\n",
      "[GET] Popular hashtags\n",
      "No data in popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'#cosmetics': 34745910,\n",
       " '#cosmeticos': 3413382,\n",
       " '#minimalismo': 2396253,\n",
       " '#cosmeticanatural': 2019661,\n",
       " '#cosmeticdentistry': 1642338,\n",
       " '#cosmeticsurgery': 1620105,\n",
       " '#cosmetica': 1534253,\n",
       " '#cosmetictattoo': 1058153,\n",
       " '#cosmeticthailand': 707848,\n",
       " '#cosmeticdentist': 614946,\n",
       " '#minimalism42': 456393,\n",
       " '#cosmeticosnaturais': 435745,\n",
       " '#cosmeticinjector': 430476,\n",
       " '#minimalisme': 405045,\n",
       " '#cosmeticsph': 396346,\n",
       " '#cosmeticavegana': 350133,\n",
       " '#cosmeticsthailand': 343754,\n",
       " '#minimalismus': 336666,\n",
       " '#cosmeticsurgeon': 336038,\n",
       " '#cosmeticbag': 308201,\n",
       " '#cosmeticdermatology': 302991,\n",
       " '#cosmetictattooing': 297009,\n",
       " '#cosmeticinjectables': 285539,\n",
       " '#cosmeticosveganos': 276251,\n",
       " '#minimalismindonesia': 216796,\n",
       " '#minimalismphotography': 113436,\n",
       " '#minimalismart': 89384,\n",
       " '#minimalismscene': 65079,\n",
       " '#minimalismodern': 50295,\n",
       " '#minimalismlife': 50151,\n",
       " '#minimalismtattoo': 48639,\n",
       " '#minimalismnusantara': 46999,\n",
       " '#minimalismdesign': 36411,\n",
       " '#minimalismstyle': 29481,\n",
       " '#minimalismworld': 26556,\n",
       " '#minimalismobrasil': 23392,\n",
       " '#minimalismartcommunity': 20988,\n",
       " '#minimalisminterior': 16882,\n",
       " '#minimalisma': 14135,\n",
       " '#minimalismfashion': 11260}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_for_hashtags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_category = user_data['content_category']\n",
    "company_description = user_data['company_description']\n",
    "query = content_category + \"|\" + company_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_news(content_category, chroma_reader, country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = HttpClient(\n",
    "    host=os.environ[\"CHROMA_IP\"],\n",
    "    port=int(os.environ[\"CHROMA_PORT\"])\n",
    ")\n",
    "collection = client.get_collection(collection_name, embedding_function=OpenAIEmbeddingFunction(api_key=os.environ[\"OPENAI_API_KEY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = collection.query(query_texts=query, n_results=20, where={\"country_code\":country_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.search(query, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.set_collection(\"current_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"List 10 important and interesting events related to any of these topics: {','.join(QUERY_TOPICS)}. \n",
    "Zomato is a popular online platform that provides a comprehensive range of services related to dining and food. Originally founded in India, Zomato has expanded globally and is now a prominent player in the food technology industry. The platform allows users to explore and discover restaurants, cafes, and eateries in their vicinity, offering detailed information such as menus, reviews, ratings, and photos.\n",
    "\n",
    "Zomato's user-friendly interface enables individuals to browse through a diverse range of cuisines, make reservations, and order food for delivery or takeaway. The platform has become a go-to resource for food enthusiasts seeking recommendations, as it aggregates user-generated reviews to help people make informed decisions about where to dine.\n",
    "\n",
    "In addition to its consumer-facing services, Zomato has also ventured into food delivery, connecting users with a wide network of restaurants and delivery partners. The platform's commitment to enhancing the overall dining experience has made it a popular choice for both food lovers and businesses in the food industry.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from utils.langchain_utils import *\n",
    "\n",
    "# environment setup\n",
    "with open(\".env\", \"r\") as key_file:\n",
    "    keys = list(key_file)\n",
    "\n",
    "for item in keys:\n",
    "    variable, value = item.split(\"=\")[0], \"=\".join(item.split(\"=\")[1:])\n",
    "    os.environ[variable] = value.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned news search:  \n",
      "\n",
      "\n",
      "FinTech OR Investment OR Stocks OR Mutual Funds OR Wealth Management OR Online Investing OR Zero Brokerage Fees OR User-Friendly App OR India OR US Stocks\n"
     ]
    }
   ],
   "source": [
    "query = \"FinTech, Investment, Stocks, mutual funds | Grow your wealth, effortlessly. Groww is your one-stop shop for all things investing in India. From stocks and mutual funds to gold and US stocks, Groww makes it simple and accessible for everyone, with a user-friendly app and zero brokerage fees. Start small, invest smartly, and watch your money blossom with Groww.\"\n",
    "country = \"IN\"\n",
    "llm_name = 'gpt-3.5-azure'\n",
    "\n",
    "industry = query.split(\"|\")[0]\n",
    "company_description = query.split(\"|\")[1]\n",
    "news_topic_template = \"\"\"What are the top 10 topic related to the {query} industry and a company with this description:\n",
    "{description}\n",
    "Only list the items as a set of comma seperated values, EG: <topic>,<topic>,...\n",
    "NO NUMBERINGS\"\"\"\n",
    "news_topic_prompt = PromptTemplate(template=news_topic_template, input_variables=['query', 'description'])\n",
    "news_topic_chain = LLMChain(llm=get_model(llm_name), prompt=news_topic_prompt, output_key=\"news_topics\")\n",
    "\n",
    "news_topics = news_topic_chain({\n",
    "    \"query\": industry,\n",
    "    \"description\": company_description\n",
    "})[\"news_topics\"]\n",
    "news_topics_query = re.sub(r\",\\s+\", \" OR \", news_topics)\n",
    "print(\"Returned news search: \", news_topics_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned news search:  \n",
      "\n",
      "FinTech OR Investment OR Stocks OR mutual funds OR wealth management OR Indian market OR user-friendly app OR zero brokerage fees OR diversified portfolio OR smart investing OR US stocks OR gold OR financial technology OR portfolio management OR investment options\n",
      "Getting headlines for \n",
      "\n",
      "FinTech OR Investment OR Stocks OR mutual funds OR wealth management OR Indian market OR user-friendly app OR zero brokerage fees OR diversified portfolio OR smart investing OR US stocks OR gold OR financial technology OR portfolio management OR investment options\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [01:35<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "news = news_from_query(query, country='IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='fe21c0b9877f49418465102f13d025cc', openai_api_base='https://buzztrends-openai-services.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='buzztrends-gpt35-turbo16k', model_version='', openai_api_type='azure', openai_api_version='2023-07-01-preview'),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model('gpt-3.5-azure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nllm\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-azure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMChain\nllm\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "LLMChain(llm=get_model('gpt-3.5-azure'), prompt=PromptTemplate(template=\"\", input_variables=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment setup\n",
    "with open(\".env\", \"r\") as key_file:\n",
    "    keys = list(key_file)\n",
    "\n",
    "for item in keys:\n",
    "    variable, value = item.split(\"=\")[0], \"=\".join(item.split(\"=\")[1:])\n",
    "    os.environ[variable] = value.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='fe21c0b9877f49418465102f13d025cc', openai_api_base='https://buzztrends-openai-services.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='buzztrends-gpt35-turbo16k', model_version='', openai_api_type='azure', openai_api_version='2023-07-01-preview'),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model('gpt-3.5-azure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"film industry\"\n",
    "target = \"text\"\n",
    "country_code = \"IN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.search(query, filter=dict(country_code=country_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = HttpClient(host=os.environ[\"CHROMA_IP\"], port=os.environ[\"CHROMA_PORT\"])\n",
    "embedding_function=OpenAIEmbeddingFunction(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\"current_events\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.get('69c1ee9c-3b34-5468-9104-abcf6546663a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"vednat is a top tier dawg. vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg vednat is a top tier dawg \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids=['08335a8d-8860-11ee-b3d3-d807c903b03b'], documents=[doc], metadatas=[{\"mr\":\"dog\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "docs_and_meta = pkl.load(open(\"test.pkl\", \"rb\"))\n",
    "\n",
    "# get links for all the topics\n",
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "\n",
    "for temp_data in docs_and_meta:\n",
    "    data = np.array(temp_data, dtype=object).T\n",
    "\n",
    "    ids.extend(list(map(lambda x: get_id(str(x[0])+str(x[1])), data)))\n",
    "    documents.extend(list(data.T[0]))\n",
    "    metadata.extend(list(data.T[1]))\n",
    "\n",
    "temp = pd.DataFrame({\n",
    "    \"ids\": ids,\n",
    "    \"documents\": documents,\n",
    "    \"metadata\": metadata\n",
    "})\n",
    "\n",
    "print(\"Total documents:\", len(temp))\n",
    "temp.drop_duplicates(\"documents\", inplace=True)\n",
    "print(\"Total documents after removing duplicates:\", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "docs_and_meta = pkl.load(open(\"test.pkl\", \"rb\"))\n",
    "\n",
    "# get links for all the topics\n",
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "\n",
    "for temp_data in docs_and_meta:\n",
    "    data = np.array(temp_data, dtype=object).T\n",
    "\n",
    "    ids.extend(list(map(lambda x: get_id(str(x[0])+str(x[1])), data)))\n",
    "    documents.extend(list(data.T[0]))\n",
    "    metadata.extend(list(data.T[1]))\n",
    "\n",
    "temp = pd.DataFrame({\n",
    "    \"ids\": ids,\n",
    "    \"documents\": documents,\n",
    "    \"metadata\": metadata\n",
    "})\n",
    "\n",
    "print(\"Total documents:\", len(temp))\n",
    "temp.drop_duplicates(\"ids\", inplace=True)\n",
    "print(\"Total documents after removing duplicates:\", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids=[str(uuid.uuid5(uuid.NAMESPACE_DNS, doc))], documents=[doc], metadatas=[{\"mr\":\"dog\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(uuid.uuid5(uuid.NAMESPACE_DNS, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(query_texts=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = results['documents'][0]\n",
    "ids = results['ids'][0]\n",
    "meta = results['metadatas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id(str(docs[0]) + str(meta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id(str(docs[1]) + str(meta[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "cases=[(str(meta[0]), str(meta[1]))] \n",
    "\n",
    "for a,b in cases:     \n",
    "    print('{} => {}'.format(a,b))  \n",
    "    for i,s in enumerate(difflib.ndiff(a, b)):\n",
    "        if s[0]==' ': continue\n",
    "        elif s[0]=='-':\n",
    "            print(u'Delete \"{}\" from position {}'.format(s[-1],i))\n",
    "        elif s[0]=='+':\n",
    "            print(u'Add \"{}\" to position {}'.format(s[-1],i))    \n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(meta[0])[635:655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(meta[1])[635:655]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_mongo_client.get_user_list()\n",
    "\n",
    "for user in users:\n",
    "    _id = user[\"company_id\"]\n",
    "    old_moments = user[\"moments\"]\n",
    "\n",
    "    new_current_events = []\n",
    "\n",
    "    for item in old_moments[\"Current Events\"]:\n",
    "        new_current_events.append({\n",
    "            \"event_name\": item[\"event_name\"],\n",
    "            \"topic\": item[\"topic\"],\n",
    "            \"validation\": {\n",
    "                \"google_trends\": item[\"validation\"][\"google_trends\"][\"keywords\"]\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_moments[\"Current Events\"] = new_current_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mongo_client.update_user_moments(100, old_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader, chroma_writer = get_reader_writer(\n",
    "    host=os.environ[\"CHROMA_IP\"],\n",
    "    port=int(os.environ[\"CHROMA_PORT\"]),\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    reader_collection_name=collection_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name=\"current_events\"\n",
    "topic=\"entertainment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_collection(chroma_reader, chroma_writer, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = get_news_by_search(f\"upcoming or ongoing major events about {topic}\", limit=50, country=country_code)\n",
    "news_df.to_csv(\"./test/news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(\"./test/news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = parse_news_url(news_df[\"url\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"text\"\n",
    "\n",
    "news_df = news_df[(news_df[\"text\"].isna() == False)]\n",
    "news_df[\"country_code\"] = [country_code] * len(news_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df:pd.DataFrame, target:str) -> tuple[list[str], list[dict]]:\n",
    "    texts = df[target].values\n",
    "\n",
    "    meta_columns = df.columns.to_list()\n",
    "    meta_columns.remove(target)\n",
    "\n",
    "    meta_df = df[meta_columns]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \".\", \",\", \"\\n\"])\n",
    "\n",
    "    documents, metadata = [], []\n",
    "\n",
    "    for i, item in enumerate(texts):\n",
    "        splits = text_splitter.split_text(item)\n",
    "        documents.extend(splits)\n",
    "        metadata.extend([meta_df.iloc[i].to_dict()] * len(splits))\n",
    "\n",
    "    return documents, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, metadata = split_df(news_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_writer.update(collection_name, documents, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"text\"\n",
    "df=news_df.copy()\n",
    "texts = df[target].values\n",
    "meta_columns = df.columns.to_list()\n",
    "meta_columns.remove(target)\n",
    "metadata = df[meta_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.set_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_events_moments = generate_current_events(chroma_reader, QUERY_TOPICS, country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"List 10 important and interesting events related to any of these topics: {','.join(QUERY_TOPICS)}.\"\n",
    "\n",
    "relevant_docs = chroma_reader.search(query, 30, {\"country_code\": country_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, metadata = load_df(news_df, page_content_column=\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"current_events\"\n",
    "\n",
    "chroma_reader.set_collection(collection_name)\n",
    "\n",
    "current_events_moments = generate_current_events(chroma_reader,QUERY_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_events_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleSearch(f\"upcoming or ongoing major events about sports tournaments\", num_results=20, country=country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_news_by_search(f\"upcoming or ongoing major events about sports tournaments\", country=country_code, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.search(f\"List 10 important and interesting events related to any of these topics: {','.join(QUERY_TOPICS)}.\", n=30, filter={\"country_code\":\"IN\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_events_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metadata(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_links = [('https://www.visitphilly.com/articles/philadelphia/top-events-and-festivals-in-philadelphia/', 'IN'), ('https://en.wikipedia.org/wiki/News', 'IN'), ('https://www.nih.gov/about-nih/what-we-do/nih-almanac/national-institute-drug-abuse-nida', 'IN'), ('https://www.cnn.com/', 'IN'), ('https://blog.twitter.com/en_us/topics/insights/2022/how-many-people-come-twitter-for-news', 'IN')]\n",
    "articles_data = [parse_for_current_events(item) for item in temp_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_key=\"source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, metadata = build_splited_docs(articles_data, target_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = articles_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \".\", \",\", \"\\n\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(page[target_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.pop(target_key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_collection(chroma_reader, chroma_writer, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_splited_docs(sitetexts):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \".\", \",\", \"\\n\"])\n",
    "\n",
    "    docs, metadatas = [], []\n",
    "    for page in sitetexts:\n",
    "        splits = text_splitter.split_text(page['text'])\n",
    "        docs.extend(splits)\n",
    "        metadatas.extend([{\"source\": page['source'], \"country_code\": page[\"country_code\"]}] * len(splits))\n",
    "\n",
    "    return docs, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(docs, metadata) = pkl.load(open(\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs = divide_chunks(docs, 1000)\n",
    "chunked_metadata = divide_chunks(metadata, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for docs, metadata in zip(chunked_docs, chunked_metadata):\n",
    "    chroma_writer.update(\"test_industry\", docs, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_writer.delete_collection(\"general_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.set_collection(\"test_industry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = chroma_reader.search(\"Indian Food\", n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = get_news_by_topic(\"SPORTS\", country=country_code, lang=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[(news_df[\"top_image\"] != \"\") & (news_df[\"keywords\"] != \"\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = parse_news_url(news_df[\"url\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"keywords\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.meta_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(df, page_content_column=\"title\"):\n",
    "    data = DataFrameLoader(df, page_content_column=page_content_column).load()\n",
    "\n",
    "    documents = [item.page_content for item in data]\n",
    "    metadata = [item.metadata for item in data]\n",
    "\n",
    "    return documents, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, metadata = load_df(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_writer.update(\"general_news\", documents, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = parse_news_url(\"https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3Lndoby5pbnQvbmV3cy9pdGVtLzEwLTExLTIwMjMtY2hpbGRyZW4td2l0aC1jYW5jZXItZXZhY3VhdGVkLWZyb20tZ2F6YS1mb3ItdHJlYXRtZW50LXRvLWVneXB0LWFuZC1qb3JkYW7SAQA?oc=5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = chroma_reader.search(\"Indian Food\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.search(\"Indian Food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_reader.set_collection(\"general_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_news(\"Diwali\", chroma_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = filtered[:5]\n",
    "industry = filtered[5:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mongo_client.update_user_moments(\n",
    "    100,\n",
    "    {\n",
    "        \"general_news\": general,\n",
    "        \"industry\": industry,\n",
    "        \"current_events\": [\n",
    "            {\n",
    "                \"event_name\": \"ICC Cricket world cup 2023\",\n",
    "                \"topic\": \"Cricket world cup hosted in India\",\n",
    "                \"validation\": {\n",
    "                    \"google_trends\": {\n",
    "                        \"keywords\": [\"cricket\", \"icc world cup\", \"india cricket\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"event_name\": \"Diwali\",\n",
    "                \"topic\": \"One of the biggest festivals in India\",\n",
    "                \"validation\": {\n",
    "                    \"google_trends\": {\n",
    "                        \"keywords\": [\"diwali\", \"indian festivals\", \"lights\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"social_media\": [\n",
    "            {\n",
    "                \"title\": \"Run the dog trends\",\n",
    "                \"hashtag\": [\"#crazydog\", \"#mrdoge\", \"#woof\"],\n",
    "                'validation': {\n",
    "                    \"hashtags\": [\n",
    "                        {\"#crazydog\": 100210,\n",
    "                         \"#mrdoge\": 100232, \n",
    "                         \"#woof\": 100311}\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Night is day? what?\",\n",
    "                \"hashtag\": [\"#idontunderstand\", \"#oogaboogabrain\", \"#what\"],\n",
    "                'validation': {\n",
    "                    \"hashtags\": [\n",
    "                        {\"#idontunderstand\": 100210,\n",
    "                         \"#oogaboogabrain\": 100232, \n",
    "                         \"#what\": 100311}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
